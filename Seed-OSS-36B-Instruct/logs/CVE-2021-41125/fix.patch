--- a/scrapy/downloadermiddlewares/httpauth.py
+++ b/scrapy/downloadermiddlewares/httpauth.py
@@ -5,6 +5,7 @@
 """
 
 from w3lib.http import basic_auth_header
+from urllib.parse import urlparse
 
 from scrapy import signals
 
@@ -22,10 +23,30 @@
     def spider_opened(self, spider):
         usr = getattr(spider, 'http_user', '')
         pwd = getattr(spider, 'http_pass', '')
+        auth_domain = getattr(spider, 'http_auth_domain', '')
         if usr or pwd:
             self.auth = basic_auth_header(usr, pwd)
+            # Parse allowed domains (supports string or list of domains)
+            if isinstance(auth_domain, str):
+                self.allowed_domains = {d.strip().lower() for d in auth_domain.split(',') if d.strip()}
+            else:
+                self.allowed_domains = {d.strip().lower() for d in auth_domain if isinstance(d, str) and d.strip()}
+        else:
+            self.allowed_domains = set()
 
     def process_request(self, request, spider):
         auth = getattr(self, 'auth', None)
-        if auth and b'Authorization' not in request.headers:
+        allowed_domains = getattr(self, 'allowed_domains', set())
+        
+        if not auth or not allowed_domains:
+            return
+            
+        # Get domain from request URL (ignore port)
+        parsed_url = urlparse(request.url)
+        domain = parsed_url.hostname.lower() if parsed_url.hostname else ''
+        
+        if domain not in allowed_domains:
+            return
+            
+        if b'Authorization' not in request.headers:
             request.headers[b'Authorization'] = auth

